import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import os

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ---
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
DATA_DIR = 'datasets/real_and_fake_face'
CLASSES = ['training_real', 'training_fake']

# --- –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —à–ª—è—Ö—É ---
if not os.path.exists(DATA_DIR):
    raise FileNotFoundError(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö: {DATA_DIR}")

print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞–ø–∫—É –∑ –¥–∞–Ω–∏–º–∏: {DATA_DIR}")

# --- –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª—ñ ---
base = MobileNetV2(include_top=False, input_shape=(*IMG_SIZE, 3), weights='imagenet')
base.trainable = False  # –∑–∞–º–æ—Ä–æ–∂—É—î–º–æ –±–∞–∑–æ–≤—É —á–∞—Å—Ç–∏–Ω—É

x = base.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.3)(x)
out = layers.Dense(1, activation='sigmoid')(x)
model = Model(base.input, out)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# --- –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö ---
datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    classes=CLASSES,
    subset='training'
)

val_gen = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    classes=CLASSES,
    subset='validation'
)

# --- –ù–∞–≤—á–∞–Ω–Ω—è ---
print("\nüöÄ –ü–æ—á–∏–Ω–∞—î–º–æ –Ω–∞–≤—á–∞–Ω–Ω—è...")
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    steps_per_epoch=train_gen.samples // BATCH_SIZE,
    validation_steps=val_gen.samples // BATCH_SIZE
)

# --- –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è ---
model.save('deepfake_detector.h5')
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ —è–∫ 'deepfake_detector.h5'")

# --- –û—Ü—ñ–Ω–∫–∞ –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó ---
val_loss, val_acc = model.evaluate(val_gen)
print(f"\nüìä –¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {val_acc * 100:.2f}%")

# --- –ì—Ä–∞—Ñ—ñ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ —ñ –≤—Ç—Ä–∞—Ç ---
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train acc')
plt.plot(history.history['val_accuracy'], label='Val acc')
plt.title('–¢–æ—á–Ω—ñ—Å—Ç—å')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train loss')
plt.plot(history.history['val_loss'], label='Val loss')
plt.title('–í—Ç—Ä–∞—Ç–∞')
plt.legend()
plt.show()

# --- –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ –∫—ñ–ª—å–∫–æ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö ---
import random

# –í–∏–±–∏—Ä–∞—î–º–æ 6 –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —ñ–∑ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É
sample_images, sample_labels = next(val_gen)
idxs = random.sample(range(len(sample_images)), 6)

plt.figure(figsize=(12, 6))
for i, idx in enumerate(idxs):
    img = sample_images[idx]
    true_label = int(sample_labels[idx])
    pred = model.predict(img[np.newaxis, ...])[0][0]
    pred_label = 1 if pred >= 0.5 else 0

    color = 'green' if pred_label == true_label else 'red'
    plt.subplot(2, 3, i + 1)
    plt.imshow(img)
    plt.title(f"Pred: {'Fake' if pred_label else 'Real'}\n({pred:.2f})", color=color)
    plt.axis('off')

plt.suptitle("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (–∑–µ–ª–µ–Ω–∏–π = –ø—Ä–∞–≤–∏–ª—å–Ω–æ)")
plt.show()
s